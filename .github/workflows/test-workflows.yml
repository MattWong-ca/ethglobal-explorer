name: ğŸ§ª Test Automation Workflows

on:
  workflow_dispatch:
    inputs:
      test_type:
        description: 'Type of test to run'
        required: true
        default: 'dry_run'
        type: choice
        options:
          - dry_run
          - single_script
          - connectivity_only
          - full_integration
      
      script_to_test:
        description: 'Script to test (if single_script selected)'
        required: false
        default: '05_scrape_hackathons.py'
        type: choice
        options:
          - 01_upload_prizes.py
          - 02_scrape_projects.py
          - 03_upload_projects.py
          - 04a_upload_hackathons.py
          - 05_scrape_hackathons.py

jobs:
  validate-environment:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    outputs:
      environment_ready: ${{ steps.check.outputs.ready }}
      missing_secrets: ${{ steps.check.outputs.missing_secrets }}
    
    steps:
      - name: ğŸ“‹ Validate environment and secrets
        id: check
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
          DISCORD_WEBHOOK_URL: ${{ secrets.DISCORD_WEBHOOK_URL }}
        run: |
          echo "ğŸ” Checking required secrets..."
          
          MISSING_SECRETS=()
          
          if [ -z "$SUPABASE_URL" ]; then
            MISSING_SECRETS+=("SUPABASE_URL")
          fi
          
          if [ -z "$SUPABASE_SERVICE_KEY" ]; then
            MISSING_SECRETS+=("SUPABASE_SERVICE_KEY")  
          fi
          
          if [ ${#MISSING_SECRETS[@]} -eq 0 ]; then
            echo "âœ… All required secrets are configured"
            echo "ready=true" >> $GITHUB_OUTPUT
            echo "missing_secrets=" >> $GITHUB_OUTPUT
          else
            echo "âŒ Missing required secrets: ${MISSING_SECRETS[*]}"
            echo "ready=false" >> $GITHUB_OUTPUT
            echo "missing_secrets=${MISSING_SECRETS[*]}" >> $GITHUB_OUTPUT
          fi
          
          # Check optional secrets
          if [ -n "$DISCORD_WEBHOOK_URL" ]; then
            echo "âœ… Discord webhook configured"
          else
            echo "â„¹ï¸  Discord webhook not configured (optional)"
          fi

  dry-run-test:
    needs: validate-environment
    if: github.event.inputs.test_type == 'dry_run' && needs.validate-environment.outputs.environment_ready == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
      - name: ğŸ“¥ Checkout repository
        uses: actions/checkout@v4

      - name: ğŸ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: ğŸ—ï¸ Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y chromium-browser chromium-chromedriver
          cd scripts
          pip install -r requirements.txt

      - name: ğŸ§ª Dry run - validate scripts without execution
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
        run: |
          cd scripts
          
          echo "ğŸ§ª Running dry-run validation..."
          
          # Check script syntax
          SCRIPTS=(
            "01_upload_prizes.py"
            "02_scrape_projects.py"
            "03_upload_projects.py" 
            "04a_upload_hackathons.py"
            "05_scrape_hackathons.py"
          )
          
          for script in "${SCRIPTS[@]}"; do
            echo "ğŸ“‹ Validating $script syntax..."
            python3 -m py_compile "$script"
            echo "âœ… $script syntax valid"
          done
          
          # Test imports and database connection
          python3 << 'EOF'
          import sys
          sys.path.append('.')
          
          print("ğŸ“‹ Testing imports...")
          try:
              from selenium import webdriver
              print("âœ… Selenium import successful")
              
              from bs4 import BeautifulSoup
              print("âœ… BeautifulSoup import successful")
              
              from supabase import create_client
              print("âœ… Supabase import successful")
              
              import os
              supabase = create_client(
                  os.getenv('SUPABASE_URL'),
                  os.getenv('SUPABASE_SERVICE_KEY')
              )
              
              # Test database connection without modifying data
              result = supabase.table('projects').select('id').limit(1).execute()
              print(f"âœ… Database connection successful")
              
          except Exception as e:
              print(f"âŒ Validation failed: {e}")
              sys.exit(1)
          EOF
          
          echo "âœ… Dry run validation completed successfully"

  single-script-test:
    needs: validate-environment
    if: github.event.inputs.test_type == 'single_script' && needs.validate-environment.outputs.environment_ready == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 60
    
    steps:
      - name: ğŸ“¥ Checkout repository
        uses: actions/checkout@v4

      - name: ğŸ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: ğŸ—ï¸ Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y chromium-browser chromium-chromedriver jq
          cd scripts
          pip install -r requirements.txt

      - name: ğŸ¯ Test single script - ${{ github.event.inputs.script_to_test }}
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
        run: |
          cd scripts
          
          SCRIPT="${{ github.event.inputs.script_to_test }}"
          echo "ğŸ§ª Testing script: $SCRIPT"
          
          START_TIME=$(date +%s)
          
          # Run with timeout
          timeout 3600 python3 "$SCRIPT" || EXIT_CODE=$?
          
          END_TIME=$(date +%s)
          DURATION=$((END_TIME - START_TIME))
          
          echo "Script duration: ${DURATION}s"
          
          if [ ${EXIT_CODE:-0} -eq 124 ]; then
            echo "âŒ Script timed out after 1 hour"
            exit 1
          elif [ ${EXIT_CODE:-0} -ne 0 ]; then
            echo "âŒ Script failed with exit code ${EXIT_CODE:-0}"
            exit ${EXIT_CODE:-1}
          else
            echo "âœ… Script completed successfully"
          fi

      - name: ğŸ“Š Analyze test results
        if: always()
        run: |
          cd scripts
          
          echo "ğŸ“Š Analyzing generated files..."
          
          # Check for generated files
          if [ -f "ethglobal_projects.json" ]; then
            SIZE=$(du -h ethglobal_projects.json | cut -f1)
            COUNT=$(jq '.projects | length' ethglobal_projects.json 2>/dev/null || echo "0")
            echo "âœ… Projects file: $SIZE, $COUNT projects"
          fi
          
          if [ -f "all_hackathons.json" ]; then
            SIZE=$(du -h all_hackathons.json | cut -f1)  
            COUNT=$(jq '.hackathons | length' all_hackathons.json 2>/dev/null || echo "0")
            echo "âœ… Hackathons file: $SIZE, $COUNT hackathons"
          fi
          
          # Check for any log files
          if ls *.log 1> /dev/null 2>&1; then
            echo "ğŸ“‹ Log files generated:"
            ls -la *.log
          fi

  connectivity-test:
    needs: validate-environment
    if: github.event.inputs.test_type == 'connectivity_only' && needs.validate-environment.outputs.environment_ready == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 20
    
    steps:
      - name: ğŸ“¥ Checkout repository
        uses: actions/checkout@v4

      - name: ğŸ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: ğŸ—ï¸ Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y chromium-browser chromium-chromedriver
          cd scripts
          pip install -r requirements.txt

      - name: ğŸ”— Test ETHGlobal website connectivity
        run: |
          echo "ğŸ”— Testing ETHGlobal website accessibility..."
          
          python3 << 'EOF'
          from selenium import webdriver
          from selenium.webdriver.support.ui import WebDriverWait
          import sys
          import time
          
          options = webdriver.ChromeOptions()
          options.add_argument('--headless')
          options.add_argument('--no-sandbox')
          options.add_argument('--disable-dev-shm-usage')
          
          driver = webdriver.Chrome(options=options)
          
          try:
              urls_to_test = [
                  "https://ethglobal.com",
                  "https://ethglobal.com/events/hackathons", 
                  "https://ethglobal.com/showcase?page=1"
              ]
              
              for url in urls_to_test:
                  print(f"ğŸ” Testing: {url}")
                  start = time.time()
                  driver.get(url)
                  
                  WebDriverWait(driver, 20).until(
                      lambda d: d.execute_script("return document.readyState") == "complete"
                  )
                  
                  load_time = time.time() - start
                  title = driver.title
                  
                  print(f"âœ… {url}")
                  print(f"   Title: {title}")
                  print(f"   Load time: {load_time:.2f}s")
                  
          except Exception as e:
              print(f"âŒ Connectivity test failed: {e}")
              sys.exit(1)
          finally:
              driver.quit()
              
          print("âœ… All connectivity tests passed")
          EOF

      - name: ğŸ—„ï¸ Test database connectivity
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
        run: |
          echo "ğŸ—„ï¸ Testing database connectivity..."
          
          python3 << 'EOF'
          import os
          from supabase import create_client
          import sys
          import time
          
          try:
              print("ğŸ” Connecting to Supabase...")
              start = time.time()
              
              supabase = create_client(
                  os.getenv('SUPABASE_URL'),
                  os.getenv('SUPABASE_SERVICE_KEY')
              )
              
              connect_time = time.time() - start
              print(f"âœ… Connection established ({connect_time:.2f}s)")
              
              # Test each table
              tables = ['projects', 'events', 'prizes', 'project_prizes']
              
              for table in tables:
                  print(f"ğŸ” Testing table: {table}")
                  start = time.time()
                  
                  result = supabase.table(table).select('*').limit(1).execute()
                  
                  query_time = time.time() - start
                  record_count = len(result.data)
                  
                  print(f"âœ… {table}: {record_count} records ({query_time:.2f}s)")
              
              print("âœ… All database connectivity tests passed")
              
          except Exception as e:
              print(f"âŒ Database connectivity test failed: {e}")
              sys.exit(1)
          EOF

  full-integration-test:
    needs: validate-environment
    if: github.event.inputs.test_type == 'full_integration' && needs.validate-environment.outputs.environment_ready == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 90
    
    steps:
      - name: ğŸ“¥ Checkout repository
        uses: actions/checkout@v4

      - name: ğŸ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: ğŸ—ï¸ Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y chromium-browser chromium-chromedriver jq
          cd scripts
          pip install -r requirements.txt

      - name: ğŸ”„ Run integration test workflow
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
        run: |
          cd scripts
          
          echo "ğŸ”„ Running full integration test..."
          echo "âš ï¸  This will test the complete data pipeline"
          
          # Run hackathon discovery first
          echo "ğŸ” Step 1: Scraping hackathons..."
          timeout 1200 python3 05_scrape_hackathons.py
          
          if [ -f "all_hackathons.json" ] && [ -s "all_hackathons.json" ]; then
            HACKATHONS=$(jq '.hackathons | length' all_hackathons.json)
            echo "âœ… Found $HACKATHONS hackathons"
          else
            echo "âŒ Hackathon scraping failed"
            exit 1
          fi
          
          # Test project scraping (limited)
          echo "ğŸ“Š Step 2: Testing project scraping (sample)..."
          
          # Modify the scraping script to only do 1 page for testing
          python3 << 'EOF'
          # Test a single page of projects
          from selenium import webdriver
          from selenium.webdriver.common.by import By
          from selenium.webdriver.support.ui import WebDriverWait
          from selenium.webdriver.support import expected_conditions as EC
          from bs4 import BeautifulSoup
          import json
          
          options = webdriver.ChromeOptions()
          options.add_argument('--headless')
          options.add_argument('--no-sandbox')
          options.add_argument('--disable-dev-shm-usage')
          options.add_argument('--disable-images')
          
          driver = webdriver.Chrome(options=options)
          
          try:
              driver.get("https://ethglobal.com/showcase?page=1")
              
              WebDriverWait(driver, 20).until(
                  EC.presence_of_element_located((By.CSS_SELECTOR, 'a[href^="/showcase/"]'))
              )
              
              soup = BeautifulSoup(driver.page_source, 'html.parser')
              project_links = soup.find_all('a', href=lambda x: x and x.startswith('/showcase/'))
              
              print(f"âœ… Found {len(project_links)} projects on sample page")
              
              if len(project_links) > 0:
                  # Create minimal test file
                  test_data = {
                      "projects": [
                          {
                              "title": "Test Project",
                              "description": "Integration test project",
                              "event": "test-event", 
                              "url": "/showcase/test",
                              "prizes": []
                          }
                      ]
                  }
                  
                  with open('test_projects.json', 'w') as f:
                      json.dump(test_data, f)
                  
                  print("âœ… Created test project data")
              else:
                  raise Exception("No projects found on sample page")
                  
          finally:
              driver.quit()
          EOF
          
          echo "âœ… Integration test completed successfully"

      - name: ğŸ“Š Generate integration report
        if: always()
        run: |
          cd scripts
          
          echo "ğŸ“Š Integration Test Report" > integration_report.txt
          echo "=========================" >> integration_report.txt
          echo "Date: $(date -u)" >> integration_report.txt
          echo "Test Type: ${{ github.event.inputs.test_type }}" >> integration_report.txt
          echo "" >> integration_report.txt
          
          # File analysis
          if [ -f "all_hackathons.json" ]; then
            SIZE=$(du -h all_hackathons.json | cut -f1)
            COUNT=$(jq '.hackathons | length' all_hackathons.json 2>/dev/null || echo "0")
            echo "Hackathons File: $SIZE ($COUNT hackathons)" >> integration_report.txt
          fi
          
          if [ -f "test_projects.json" ]; then
            SIZE=$(du -h test_projects.json | cut -f1)
            echo "Test Projects File: $SIZE" >> integration_report.txt
          fi
          
          echo "" >> integration_report.txt
          echo "Status: ${{ job.status }}" >> integration_report.txt
          
          cat integration_report.txt

      - name: ğŸ’¾ Upload test artifacts
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: test-results-${{ github.event.inputs.test_type }}-${{ github.run_number }}
          path: |
            scripts/*.json
            scripts/*.txt
            scripts/*.log
          retention-days: 7

  report-results:
    needs: [validate-environment, dry-run-test, single-script-test, connectivity-test, full-integration-test]
    if: always()
    runs-on: ubuntu-latest
    
    steps:
      - name: ğŸ“Š Generate test summary
        run: |
          echo "ğŸ§ª Test Workflow Summary"
          echo "======================="
          echo "Test Type: ${{ github.event.inputs.test_type }}"
          echo "Environment Ready: ${{ needs.validate-environment.outputs.environment_ready }}"
          
          if [ "${{ needs.validate-environment.outputs.environment_ready }}" = "false" ]; then
            echo "âŒ Environment validation failed"
            echo "Missing secrets: ${{ needs.validate-environment.outputs.missing_secrets }}"
          else
            echo "âœ… Environment validation passed"
          fi
          
          # Job results
          echo ""
          echo "Job Results:"
          echo "- Dry Run: ${{ needs.dry-run-test.result || 'skipped' }}"
          echo "- Single Script: ${{ needs.single-script-test.result || 'skipped' }}"  
          echo "- Connectivity: ${{ needs.connectivity-test.result || 'skipped' }}"
          echo "- Full Integration: ${{ needs.full-integration-test.result || 'skipped' }}"

      - name: ğŸ“¢ Send test results notification
        if: secrets.DISCORD_WEBHOOK_URL
        env:
          DISCORD_WEBHOOK_URL: ${{ secrets.DISCORD_WEBHOOK_URL }}
        run: |
          # Determine overall status
          if [ "${{ needs.validate-environment.outputs.environment_ready }}" = "false" ]; then
            STATUS="âŒ Environment Issues"
            COLOR=15158332
          elif [[ "${{ needs.dry-run-test.result }}" == "failure" ]] || [[ "${{ needs.single-script-test.result }}" == "failure" ]] || [[ "${{ needs.connectivity-test.result }}" == "failure" ]] || [[ "${{ needs.full-integration-test.result }}" == "failure" ]]; then
            STATUS="âŒ Test Failed"
            COLOR=15158332
          else
            STATUS="âœ… Tests Passed"
            COLOR=3066993
          fi
          
          EMBED='{
            "embeds": [{
              "title": "ğŸ§ª Automation Test Results",
              "description": "Test Type: **'${{ github.event.inputs.test_type }}'**\nStatus: **'$STATUS'**",
              "color": '$COLOR',
              "fields": [
                {
                  "name": "Test Results",
                  "value": "Dry Run: '${{ needs.dry-run-test.result || 'skipped' }}'\nSingle Script: '${{ needs.single-script-test.result || 'skipped' }}'\nConnectivity: '${{ needs.connectivity-test.result || 'skipped' }}'\nFull Integration: '${{ needs.full-integration-test.result || 'skipped' }}'",
                  "inline": true
                },
                {
                  "name": "Environment",
                  "value": "Ready: '${{ needs.validate-environment.outputs.environment_ready }}'\nMissing Secrets: '${{ needs.validate-environment.outputs.missing_secrets || 'none' }}'",
                  "inline": true
                }
              ],
              "timestamp": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'",
              "footer": {
                "text": "ETHGlobal Explorer â€¢ Test Workflow"
              }
            }]
          }'
          
          curl -X POST "$DISCORD_WEBHOOK_URL" \
            -H "Content-Type: application/json" \
            -d "$EMBED"