name: 🧪 Test Automation Workflows

on:
  workflow_dispatch:
    inputs:
      test_type:
        description: 'Type of test to run'
        required: true
        default: 'dry_run'
        type: choice
        options:
          - dry_run
          - single_script
          - connectivity_only
          - full_integration
      
      script_to_test:
        description: 'Script to test (if single_script selected)'
        required: false
        default: '05_scrape_hackathons.py'
        type: choice
        options:
          - 01_upload_prizes.py
          - 02_scrape_projects.py
          - 03_upload_projects.py
          - 04a_upload_hackathons.py
          - 05_scrape_hackathons.py

jobs:
  validate-environment:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    outputs:
      environment_ready: ${{ steps.check.outputs.ready }}
      missing_secrets: ${{ steps.check.outputs.missing_secrets }}
    
    steps:
      - name: 📋 Validate environment and secrets
        id: check
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
          DISCORD_WEBHOOK_URL: ${{ secrets.DISCORD_WEBHOOK_URL }}
        run: |
          echo "🔍 Checking required secrets..."
          
          MISSING_SECRETS=()
          
          if [ -z "$SUPABASE_URL" ]; then
            MISSING_SECRETS+=("SUPABASE_URL")
          fi
          
          if [ -z "$SUPABASE_SERVICE_KEY" ]; then
            MISSING_SECRETS+=("SUPABASE_SERVICE_KEY")  
          fi
          
          if [ ${#MISSING_SECRETS[@]} -eq 0 ]; then
            echo "✅ All required secrets are configured"
            echo "ready=true" >> $GITHUB_OUTPUT
            echo "missing_secrets=" >> $GITHUB_OUTPUT
          else
            echo "❌ Missing required secrets: ${MISSING_SECRETS[*]}"
            echo "ready=false" >> $GITHUB_OUTPUT
            echo "missing_secrets=${MISSING_SECRETS[*]}" >> $GITHUB_OUTPUT
          fi
          
          # Check optional secrets
          if [ -n "$DISCORD_WEBHOOK_URL" ]; then
            echo "✅ Discord webhook configured"
          else
            echo "ℹ️  Discord webhook not configured (optional)"
          fi

  dry-run-test:
    needs: validate-environment
    if: github.event.inputs.test_type == 'dry_run' && needs.validate-environment.outputs.environment_ready == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
      - name: 📥 Checkout repository
        uses: actions/checkout@v4

      - name: 🐍 Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: 🏗️ Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y chromium-browser chromium-chromedriver
          cd scripts
          pip install -r requirements.txt

      - name: 🧪 Dry run - validate scripts without execution
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
        run: |
          cd scripts
          
          echo "🧪 Running dry-run validation..."
          
          # Check script syntax
          SCRIPTS=(
            "01_upload_prizes.py"
            "02_scrape_projects.py"
            "03_upload_projects.py" 
            "04a_upload_hackathons.py"
            "05_scrape_hackathons.py"
          )
          
          for script in "${SCRIPTS[@]}"; do
            echo "📋 Validating $script syntax..."
            python3 -m py_compile "$script"
            echo "✅ $script syntax valid"
          done
          
          # Test imports and database connection
          python3 << 'EOF'
          import sys
          sys.path.append('.')
          
          print("📋 Testing imports...")
          try:
              from selenium import webdriver
              print("✅ Selenium import successful")
              
              from bs4 import BeautifulSoup
              print("✅ BeautifulSoup import successful")
              
              from supabase import create_client
              print("✅ Supabase import successful")
              
              import os
              supabase = create_client(
                  os.getenv('SUPABASE_URL'),
                  os.getenv('SUPABASE_SERVICE_KEY')
              )
              
              # Test database connection without modifying data
              result = supabase.table('projects').select('id').limit(1).execute()
              print(f"✅ Database connection successful")
              
          except Exception as e:
              print(f"❌ Validation failed: {e}")
              sys.exit(1)
          EOF
          
          echo "✅ Dry run validation completed successfully"

  single-script-test:
    needs: validate-environment
    if: github.event.inputs.test_type == 'single_script' && needs.validate-environment.outputs.environment_ready == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 60
    
    steps:
      - name: 📥 Checkout repository
        uses: actions/checkout@v4

      - name: 🐍 Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: 🏗️ Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y chromium-browser chromium-chromedriver jq
          cd scripts
          pip install -r requirements.txt

      - name: 🎯 Test single script - ${{ github.event.inputs.script_to_test }}
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
        run: |
          cd scripts
          
          SCRIPT="${{ github.event.inputs.script_to_test }}"
          echo "🧪 Testing script: $SCRIPT"
          
          START_TIME=$(date +%s)
          
          # Run with timeout
          timeout 3600 python3 "$SCRIPT" || EXIT_CODE=$?
          
          END_TIME=$(date +%s)
          DURATION=$((END_TIME - START_TIME))
          
          echo "Script duration: ${DURATION}s"
          
          if [ ${EXIT_CODE:-0} -eq 124 ]; then
            echo "❌ Script timed out after 1 hour"
            exit 1
          elif [ ${EXIT_CODE:-0} -ne 0 ]; then
            echo "❌ Script failed with exit code ${EXIT_CODE:-0}"
            exit ${EXIT_CODE:-1}
          else
            echo "✅ Script completed successfully"
          fi

      - name: 📊 Analyze test results
        if: always()
        run: |
          cd scripts
          
          echo "📊 Analyzing generated files..."
          
          # Check for generated files
          if [ -f "ethglobal_projects.json" ]; then
            SIZE=$(du -h ethglobal_projects.json | cut -f1)
            COUNT=$(jq '.projects | length' ethglobal_projects.json 2>/dev/null || echo "0")
            echo "✅ Projects file: $SIZE, $COUNT projects"
          fi
          
          if [ -f "all_hackathons.json" ]; then
            SIZE=$(du -h all_hackathons.json | cut -f1)  
            COUNT=$(jq '.hackathons | length' all_hackathons.json 2>/dev/null || echo "0")
            echo "✅ Hackathons file: $SIZE, $COUNT hackathons"
          fi
          
          # Check for any log files
          if ls *.log 1> /dev/null 2>&1; then
            echo "📋 Log files generated:"
            ls -la *.log
          fi

  connectivity-test:
    needs: validate-environment
    if: github.event.inputs.test_type == 'connectivity_only' && needs.validate-environment.outputs.environment_ready == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 20
    
    steps:
      - name: 📥 Checkout repository
        uses: actions/checkout@v4

      - name: 🐍 Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: 🏗️ Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y chromium-browser chromium-chromedriver
          cd scripts
          pip install -r requirements.txt

      - name: 🔗 Test ETHGlobal website connectivity
        run: |
          echo "🔗 Testing ETHGlobal website accessibility..."
          
          python3 << 'EOF'
          from selenium import webdriver
          from selenium.webdriver.support.ui import WebDriverWait
          import sys
          import time
          
          options = webdriver.ChromeOptions()
          options.add_argument('--headless')
          options.add_argument('--no-sandbox')
          options.add_argument('--disable-dev-shm-usage')
          
          driver = webdriver.Chrome(options=options)
          
          try:
              urls_to_test = [
                  "https://ethglobal.com",
                  "https://ethglobal.com/events/hackathons", 
                  "https://ethglobal.com/showcase?page=1"
              ]
              
              for url in urls_to_test:
                  print(f"🔍 Testing: {url}")
                  start = time.time()
                  driver.get(url)
                  
                  WebDriverWait(driver, 20).until(
                      lambda d: d.execute_script("return document.readyState") == "complete"
                  )
                  
                  load_time = time.time() - start
                  title = driver.title
                  
                  print(f"✅ {url}")
                  print(f"   Title: {title}")
                  print(f"   Load time: {load_time:.2f}s")
                  
          except Exception as e:
              print(f"❌ Connectivity test failed: {e}")
              sys.exit(1)
          finally:
              driver.quit()
              
          print("✅ All connectivity tests passed")
          EOF

      - name: 🗄️ Test database connectivity
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
        run: |
          echo "🗄️ Testing database connectivity..."
          
          python3 << 'EOF'
          import os
          from supabase import create_client
          import sys
          import time
          
          try:
              print("🔍 Connecting to Supabase...")
              start = time.time()
              
              supabase = create_client(
                  os.getenv('SUPABASE_URL'),
                  os.getenv('SUPABASE_SERVICE_KEY')
              )
              
              connect_time = time.time() - start
              print(f"✅ Connection established ({connect_time:.2f}s)")
              
              # Test each table
              tables = ['projects', 'events', 'prizes', 'project_prizes']
              
              for table in tables:
                  print(f"🔍 Testing table: {table}")
                  start = time.time()
                  
                  result = supabase.table(table).select('*').limit(1).execute()
                  
                  query_time = time.time() - start
                  record_count = len(result.data)
                  
                  print(f"✅ {table}: {record_count} records ({query_time:.2f}s)")
              
              print("✅ All database connectivity tests passed")
              
          except Exception as e:
              print(f"❌ Database connectivity test failed: {e}")
              sys.exit(1)
          EOF

  full-integration-test:
    needs: validate-environment
    if: github.event.inputs.test_type == 'full_integration' && needs.validate-environment.outputs.environment_ready == 'true'
    runs-on: ubuntu-latest
    timeout-minutes: 90
    
    steps:
      - name: 📥 Checkout repository
        uses: actions/checkout@v4

      - name: 🐍 Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: 🏗️ Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y chromium-browser chromium-chromedriver jq
          cd scripts
          pip install -r requirements.txt

      - name: 🔄 Run integration test workflow
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
        run: |
          cd scripts
          
          echo "🔄 Running full integration test..."
          echo "⚠️  This will test the complete data pipeline"
          
          # Run hackathon discovery first
          echo "🔍 Step 1: Scraping hackathons..."
          timeout 1200 python3 05_scrape_hackathons.py
          
          if [ -f "all_hackathons.json" ] && [ -s "all_hackathons.json" ]; then
            HACKATHONS=$(jq '.hackathons | length' all_hackathons.json)
            echo "✅ Found $HACKATHONS hackathons"
          else
            echo "❌ Hackathon scraping failed"
            exit 1
          fi
          
          # Test project scraping (limited)
          echo "📊 Step 2: Testing project scraping (sample)..."
          
          # Modify the scraping script to only do 1 page for testing
          python3 << 'EOF'
          # Test a single page of projects
          from selenium import webdriver
          from selenium.webdriver.common.by import By
          from selenium.webdriver.support.ui import WebDriverWait
          from selenium.webdriver.support import expected_conditions as EC
          from bs4 import BeautifulSoup
          import json
          
          options = webdriver.ChromeOptions()
          options.add_argument('--headless')
          options.add_argument('--no-sandbox')
          options.add_argument('--disable-dev-shm-usage')
          options.add_argument('--disable-images')
          
          driver = webdriver.Chrome(options=options)
          
          try:
              driver.get("https://ethglobal.com/showcase?page=1")
              
              WebDriverWait(driver, 20).until(
                  EC.presence_of_element_located((By.CSS_SELECTOR, 'a[href^="/showcase/"]'))
              )
              
              soup = BeautifulSoup(driver.page_source, 'html.parser')
              project_links = soup.find_all('a', href=lambda x: x and x.startswith('/showcase/'))
              
              print(f"✅ Found {len(project_links)} projects on sample page")
              
              if len(project_links) > 0:
                  # Create minimal test file
                  test_data = {
                      "projects": [
                          {
                              "title": "Test Project",
                              "description": "Integration test project",
                              "event": "test-event", 
                              "url": "/showcase/test",
                              "prizes": []
                          }
                      ]
                  }
                  
                  with open('test_projects.json', 'w') as f:
                      json.dump(test_data, f)
                  
                  print("✅ Created test project data")
              else:
                  raise Exception("No projects found on sample page")
                  
          finally:
              driver.quit()
          EOF
          
          echo "✅ Integration test completed successfully"

      - name: 📊 Generate integration report
        if: always()
        run: |
          cd scripts
          
          echo "📊 Integration Test Report" > integration_report.txt
          echo "=========================" >> integration_report.txt
          echo "Date: $(date -u)" >> integration_report.txt
          echo "Test Type: ${{ github.event.inputs.test_type }}" >> integration_report.txt
          echo "" >> integration_report.txt
          
          # File analysis
          if [ -f "all_hackathons.json" ]; then
            SIZE=$(du -h all_hackathons.json | cut -f1)
            COUNT=$(jq '.hackathons | length' all_hackathons.json 2>/dev/null || echo "0")
            echo "Hackathons File: $SIZE ($COUNT hackathons)" >> integration_report.txt
          fi
          
          if [ -f "test_projects.json" ]; then
            SIZE=$(du -h test_projects.json | cut -f1)
            echo "Test Projects File: $SIZE" >> integration_report.txt
          fi
          
          echo "" >> integration_report.txt
          echo "Status: ${{ job.status }}" >> integration_report.txt
          
          cat integration_report.txt

      - name: 💾 Upload test artifacts
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: test-results-${{ github.event.inputs.test_type }}-${{ github.run_number }}
          path: |
            scripts/*.json
            scripts/*.txt
            scripts/*.log
          retention-days: 7

  report-results:
    needs: [validate-environment, dry-run-test, single-script-test, connectivity-test, full-integration-test]
    if: always()
    runs-on: ubuntu-latest
    
    steps:
      - name: 📊 Generate test summary
        run: |
          echo "🧪 Test Workflow Summary"
          echo "======================="
          echo "Test Type: ${{ github.event.inputs.test_type }}"
          echo "Environment Ready: ${{ needs.validate-environment.outputs.environment_ready }}"
          
          if [ "${{ needs.validate-environment.outputs.environment_ready }}" = "false" ]; then
            echo "❌ Environment validation failed"
            echo "Missing secrets: ${{ needs.validate-environment.outputs.missing_secrets }}"
          else
            echo "✅ Environment validation passed"
          fi
          
          # Job results
          echo ""
          echo "Job Results:"
          echo "- Dry Run: ${{ needs.dry-run-test.result || 'skipped' }}"
          echo "- Single Script: ${{ needs.single-script-test.result || 'skipped' }}"  
          echo "- Connectivity: ${{ needs.connectivity-test.result || 'skipped' }}"
          echo "- Full Integration: ${{ needs.full-integration-test.result || 'skipped' }}"

      - name: 📢 Send test results notification
        if: secrets.DISCORD_WEBHOOK_URL
        env:
          DISCORD_WEBHOOK_URL: ${{ secrets.DISCORD_WEBHOOK_URL }}
        run: |
          # Determine overall status
          if [ "${{ needs.validate-environment.outputs.environment_ready }}" = "false" ]; then
            STATUS="❌ Environment Issues"
            COLOR=15158332
          elif [[ "${{ needs.dry-run-test.result }}" == "failure" ]] || [[ "${{ needs.single-script-test.result }}" == "failure" ]] || [[ "${{ needs.connectivity-test.result }}" == "failure" ]] || [[ "${{ needs.full-integration-test.result }}" == "failure" ]]; then
            STATUS="❌ Test Failed"
            COLOR=15158332
          else
            STATUS="✅ Tests Passed"
            COLOR=3066993
          fi
          
          EMBED='{
            "embeds": [{
              "title": "🧪 Automation Test Results",
              "description": "Test Type: **'${{ github.event.inputs.test_type }}'**\nStatus: **'$STATUS'**",
              "color": '$COLOR',
              "fields": [
                {
                  "name": "Test Results",
                  "value": "Dry Run: '${{ needs.dry-run-test.result || 'skipped' }}'\nSingle Script: '${{ needs.single-script-test.result || 'skipped' }}'\nConnectivity: '${{ needs.connectivity-test.result || 'skipped' }}'\nFull Integration: '${{ needs.full-integration-test.result || 'skipped' }}'",
                  "inline": true
                },
                {
                  "name": "Environment",
                  "value": "Ready: '${{ needs.validate-environment.outputs.environment_ready }}'\nMissing Secrets: '${{ needs.validate-environment.outputs.missing_secrets || 'none' }}'",
                  "inline": true
                }
              ],
              "timestamp": "'$(date -u +%Y-%m-%dT%H:%M:%SZ)'",
              "footer": {
                "text": "ETHGlobal Explorer • Test Workflow"
              }
            }]
          }'
          
          curl -X POST "$DISCORD_WEBHOOK_URL" \
            -H "Content-Type: application/json" \
            -d "$EMBED"